---
title: "Crossover Trials"
output: 
  html_document:
    keep_md: true
---

# Introduction 

For this tutorial we will be working with a dataset from a standard 2-period, 2-treatment AB:BA crossover trial of a treatment aimed at lowering blood pressure in people who usually have mildly-evaluated values. In other words, each person in the trial gets exposed to each intervention (active vs placebo), but in one of two possible sequences (active first vs placebo first). 

# Getting the data ready

As usual, we will first load the necessary packages and bring in the dataset. 

```{r setup, include = FALSE}

  knitr::opts_chunk$set(message = FALSE, warning = FALSE)

# Install/load packages

  packs <- c("tidyverse", "knitr", "viridis", "broom", "lme4", "sjPlot", 
             "summarytools", "readr", "flextable")
  install.packages(packs[!packs %in% installed.packages()])
  lapply(packs, library, character.only = TRUE)
  
# Import the dataset from github
  data <- read_csv("https://raw.githubusercontent.com/CRFCSDAU/EH6126_data_analysis_tutorials/master/Unit_3_Crossover_Trials/data/data.csv")

```

Have a look at the dataset. 

```{r inspect_data_1}

# View(data)

# view(dfSummary(data))

```


```{r dfsummary_table1, eval = knitr::opts_knit$get("rmarkdown.pandoc.to") == "html"}

  print(summarytools::dfSummary(data, style = "grid", plain.ascii = FALSE), 
    method = "render")

```

```{r}

# We should add labels for sex

  data$sex <- factor(data$sex, labels = c("Males", "Females"))

# Challange: Based on the information available in the dataset, how could you
# confirm that 0 = Males and 1 = Females, as I have coded it here?

```


We can see there are 4 SBP values per patient (row). These are the start and end values for each of the two periods. To visualize and analyze these data correctly, we need to convert the dataset so that it's "long", i.e. one row for each patient/time-point (more on why we do this below).

```{r reshape}

# Being able to switch between wide and long datasets is important for both
# modeling and plotting data. 

# "Wide" data:
#  ID   Time1Measure  T2M  T3M   T4M
#   1        85        82   83    81
#   2        45        96   32    99

# "Long" data:
#  ID  Time  Measure
#   1    1    85
#   1    2    82
#   1    3    83
#   1    4    81

# Reshape the data on 4 SBP values in order to plot the within period changes
# by tx group, get missing values. See functions.R

  data_long <- gather(data, time, value, starts_with("sbp")) %>%
    select(sequence, treatment_p1, treatment_p2, time, value, subj_id, sex, 
           everything()) %>%
    mutate(sequence = factor(sequence), treatment_p1 = factor(treatment_p1),
           treatment_p2 = factor(treatment_p2))

# view(dfSummary(data_long))

```

Now you can see there are five timepoints (screening, plus the start and end values for each of the two periods), each with 83 observations, which is the number of study participants. 

Now let's clean up the data a bit. 

```{r clean}

  data_long$time <- gsub("sbp__|sbp", "", data_long$time) # remove extraneous info

# Just reordering the levels so they match time. This will help when we plot
# the data. 
  times <- c("b_p1", "ep_p1", "b_p2", "ep_p2")

  data_long <- mutate(data_long, time = factor(time, levels = times)) 
# table(data_long$time)

# Create a new variable to reflect the period  
  data_long$period[grepl("_p1", data_long$time)] <- "First"
  data_long$period[grepl("_p2", data_long$time)] <- "Second"

# Create a new variable to reflect start (baseline) or end of period  
  bp <- grepl("b_p",  data_long$time) # Baseline times
  ep <- grepl("ep_p", data_long$time) # End times

  data_long$timing[bp] <- "Baseline"
  data_long$timing[ep] <- "EoP"
  
# with(data_long, table(period, timing))  

# These are the same info but we'll use them in the models below where I'll 
# explain why we want them split into 2 columns like this.   
  data_long$bl[bp] <- data_long$value[bp] # Baseline SBPs
  data_long$ep[ep] <- data_long$value[ep] # End SBPs

# Treatment indicator  
  p1 <- data_long$period == "First"  & !is.na(data_long$period)
  p2 <- data_long$period == "Second" & !is.na(data_long$period)
  data_long$tx[p1] <- data_long$treatment_p1[p1]
  data_long$tx[p2] <- data_long$treatment_p2[p2]

  data_long <- filter(data_long, !is.na(time)) %>%
    arrange(subj_id, period, timing) %>%
    select(subj_id, sequence, period, timing, tx, value, everything()) %>%
    mutate(period = factor(period),
           timing = factor(timing),
           tx  = factor(tx))

  data_long$time2 <- factor(
    data_long$time, 
    labels = c("p1_b", "p1_ep", "p2_b", "p2_ep")
    )

# View(data_long)
  
# view(dfSummary(data_long))
  

```

Now plot the data in a way that shows the overall structure. 

```{r cross_over_plot}

  ggplot(data_long, aes(x = time2, y = value, group = subj_id)) +
    geom_line(data = filter(data_long, as.numeric(time) < 3), alpha = 0.2,
              aes(color = treatment_p1)) +
    geom_smooth(data = filter(data_long, as.numeric(time) < 3), method = "lm",
                aes(color = treatment_p1, linetype = treatment_p1,
                group = treatment_p1),
                se = FALSE, size = 2) +
    geom_line(data = filter(data_long, as.numeric(time) > 2), alpha = 0.2,
              aes(color = treatment_p2)) +
    geom_smooth(data = filter(data_long, as.numeric(time) > 2), method = "lm",
                aes(color = treatment_p2, linetype = treatment_p2,
                    group = treatment_p2),
                se = FALSE, size = 2) +
    scale_linetype(guide = FALSE) +
    theme_minimal() +
    scale_color_brewer("Tx", palette = "Set1") +
    theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
    scale_x_discrete(labels = c("Start P1", "End P1", "Start P2", "End P2")) +
    xlab("") +
    ylab("SBP mmHg")

```

Here we can get a sense of the variability in SBP both within- and between-people. There seems to be quite a lot of both as it happens. We'll dig into this a bit more below. We can also see that the mean change for both groups in both periods is pretty similar.  

```{r distribution_plot}

# Distribution plot

  ggplot(data_long, aes(x = value, fill = tx, color = tx)) +
    geom_density(alpha = 0.7) +
    geom_rug() +
    scale_fill_brewer("Tx", palette = "Set1") +
    scale_color_brewer("Tx", palette = "Set1") +
    facet_wrap(~period + timing) +
    theme_minimal() +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
    ylab("") +
    xlab("SBP mmHg")

```
This is just another look at the overall distribution of SBP by period and treatment, showing a great deal of overlap. 

Note on long/wide data: 

A key concept in plotting with ggplot is that we map variables onto different aesthetics. Aesthetics are things like distances along the x and y axes, colors, and facets. We needed to convert our data from wide to long, because we can only map one variable onto any one aesthetic. So by going from wide to long, we turned our 4 time-specific SBP variables into 2 variables - one for time and one for the actual SBP value. Then we could map the SBP values to the y axis, and time to the x axis. As an exercise, you might sit with a pen and paper and try to figure out how to map 4 separate SBP variables onto a set of aesthetics that would make for a sensible plot (but don't take too much time, because you can't!).  

Being able to switch between long and wide also matters for modeling the data. For example, for a linear regression of an outcome where you want to also adjust for the baseline values of that variable, you need the data in a wide format, where each row is an observation (e.g. a patient) and there is only one row per observation. Thus the two measures at baseline and the end of the study are contained in two different columns. However, if we were doing a paired analysis, as we will below, we would need the data in a long format, where each row corresponds to a specific patient and time, and thus the information for the outcome and baseline measurements can be contained in a single column. 

# Between vs within-person variance

The main advantage of a crossover trial is that you get to evaluate your treatment against the backdrop of the within-person variability of the outcome, which is usually less variable than the between-person variability that comes into play in a parallel trial. Remember, the variance is just the average squared-distance between each measurement and the mean; and the larger it is, the more "spread out" the data are from the mean. 

First, let's look at the between-person variability for the 4 SBP measurements. 

```{r}

  data_long %>%
    group_by(time) %>%
    summarise(
      n = n(), 
      variance = var(value, na.rm = TRUE)
      )

```
Now, let's look at all the within-person variances. There are 83 of them, so we'll plot them to make it easier to take them all in. I've also added reference lines at 150 and 210, the lowest and highest of the between-person variances above. 

```{r}

  data_long %>%
    group_by(subj_id) %>%
    summarise(
      n = n(), 
      variance = var(value, na.rm = TRUE)
      ) %>%
  ggplot(aes(x = variance)) +
    geom_histogram() +
    geom_vline(xintercept = c(150, 210))
    

```
It should be clear that the within-person variances are well below the observed between-person variances. 

We can also look at this from the perspective of a linear model, and adjust for person (just like we might adjust for any other categorical variable). This model will thus report 82 (83 - 1) different means (i.e. person-specific intercepts). Take note of the R2 value, which is the % of the outcome variance explained. 

```{r}

  lm(value ~ subj_id, data = data_long) %>%
  tab_model()

```

Once we've scrolled to the bottom, you'll see that the model explains 75% of the variability. Just like we saw in the [change score tutorial](https://github.com/CRFCSDAU/EH6126_data_analysis_tutorials/tree/master/Unit_1_Review/Change_scores), adjusting for person like this (we call this using a "fixed-effect" for person), essentially eliminates all of that variability, leaving less variability against which to try and detect our treatment effect. Below we will use what's called a random effect for person, which is just a more sophisticated way of doing this. 

# Tests

Now we can model the effect of the treatment, though I suspect that you already have some idea of what it might be! Before we move on to full models though, let's have a look in terms of statistical tests - [namely the t-test and paired t-test](https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/7-t-tests). 

In this design we have a set of end-of-period SBP values for 2 periods. Thus every participant has 2 outcomes - one at the end of a period where they were on the active treatment and one where they were on the control. 

First let's ignore the fact that we have paired measures (2 per participant) and just use the good old t-test (since our outcome is continuously measured without any excessive skewness). 

```{r}

# Get rid of period specific start values
  dta <- filter(data_long, timing == "EoP")  

  t.test(dta$value[dta$tx == 1], dta$value[dta$tx == 2])

```

Very quickly, what happens if we use a linear regression instead of the t-test?

```{r}

  summary(lm(value ~ tx, data = dta))

```

Same! All tests can be recast as special cases of a linear model, which is why we focus on models so much.
 
Now let's look at the paired t-test. This will respect the fact that we have multiple measurements (2) per person. 

```{r}

  dta <- filter(data_long, timing == "EoP") %>%
    arrange(subj_id) 
# I am just making sure they are in the right order since the function for the
# paired t-test just wants 2 vectors of values and *assumes* they are in the
# same order. So we want to double check this.

# table(dta$subj_id[dta$tx == 1] == dta$subj_id[dta$tx == 2]) # All true

  t.test(dta$value[dta$tx == 1], dta$value[dta$tx == 2], paired = TRUE)

```

Same basic result (no difference in the means comparing the two sets of observations), but you can see that the CI is now much narrower. This is because the paired t-test is based on the within-participant difference in outcomes under each treatment regime. By taking differences like this, we eliminate the between person variation. For example, the following two pairs of values [(150, 153); (89, 92)] are different in that one pair is clearly much larger than the other, but the within-pair difference is the same. So let's make a simple table with the values under each treatment and their differences, by patient. 

```{r}

  table <- data_frame(
    id = unique(dta$subj_id), 
    tx_1_sbp = dta$value[dta$tx == 1], 
    tx_2_sbp = dta$value[dta$tx == 2], 
    diff = tx_2_sbp - tx_1_sbp
  ) 

  flextable(table)

```

Now lets look at the standard errors of each of the 3 columns of outcome data (the SBP under each tx, and their difference)

```{r}

  map(table[2:4], function(x)sd(x, na.rm = TRUE)/sqrt(83))

```

Challenge: Go back and compare those SE values to the CIs from the unpaired and paired t-tests, remembering that the upper limit of the 95% CI will be the estimate + (1.96 * SE). Do they match?

This is the strength of the crossover design - a smaller SE, which means a more precise estimate of our treatment effect. 


# Models

Now we've demonstrated the basics of why the crossover design works by looking at the paired t-test. However, we also want to incorporate other information, like covariates. To do this, we'll used what are called [mixed-effects models or multi-level models](https://en.wikipedia.org/wiki/Multilevel_model). They are pretty much just like the linear regression models you are used to, but they include an effect for "clustering", which is where you have more than one observation per unit (e.g. 2 measurements for each participant). Just like the regression model above where we included a fixed effect for participant (effectively fitting a separate intercept for each patient), using the mixed-effects model also removes the between-participant variability from the outcome, resulting in effect estimates with narrower SEs. 

Now we'll use these models to make different adjustments for things like prognostic covariates (sex), period specific effects, and period-specific baseline (start) values. 

```{r models}

# Models

# Re-configure the data so we can adjust for period-specific baselines if we
# want to. 

  me_sbp_df <- full_join(
    select(data_long, subj_id, sex, period, bl, tx) %>% filter(!is.na(bl)),
    select(data_long, subj_id, sex, period, ep, tx) %>% filter(!is.na(ep)),
    by = c("subj_id", "period", "tx", "sex")
  ) %>%
    mutate(bl = scale(bl, scale = FALSE))


# 4 models. Adjust for sex; + period; +tx*period interaction; +bl
  me_sbp     <- lmer(ep ~ tx + sex +               (1 | subj_id),
                     data = me_sbp_df)
  me_sbp_p   <- lmer(ep ~ tx + sex + period +      (1 | subj_id),
                     data = me_sbp_df)
  me_sbp_int <- lmer(ep ~ tx * period +  sex +     (1 | subj_id),
                     data = me_sbp_df)
  me_sbp_bl  <- lmer(ep ~ tx + sex + period + bl + (1 | subj_id),
                     data = me_sbp_df)

  labs <- c("Intercept", "Active Tx (vs Control)", "Female (vs Male)", 
            "Period (2 vs 1)")

  tab_model(
    me_sbp, me_sbp_p, me_sbp_bl,
    show.se = TRUE,
    p.val = "kr",
    pred.labels = c(labs, "SBP Baseline"),
    dv.labels = c("Unadjusted", "+ Period effect", "+ Baselines")
    )

```

When interpreting these tables, the top half (every thing above "Random Effects") is what you are more used to seeing in a regression table. These are the "fixed effects" for all the predictors in the model, and they are interpreted the same way you are used to: the difference in the mean outcome for a 1 unit increase in the predictor. So based on the first model, women have a mean SBP that is 2.94 mmHg lower than males (though the estimate has a very wide CI and a large p-value). 

All of the stuff below "Random Effects" are what we call the variance components of the model. Looking at the first model, you see $\sigma^{2}$ and $\tau{00}$. The latter of these, 144.89 is the variance explained by the random effect of patient (subj_id); while $\sigma^{2}$ is the residual variance (the outcome variance not explained by the patient level random effect). The ratio of $\tau{00}$ to the total variance ($\tau{00} + \sigma^{2}$) is 0.71, which is labeled as the ICC, which we can now interpret at the % of total variance explained by the patient level effect. This is, not coincidentally, close to the 75% of variance explained in the regression model we looked at before with a fixed effect for person.  

Returning back to the fixed effects of the model, they confirm what we probably should have expected from the plotting, which is that there was no appreciable effect on the outcome. But just for fun, now we will add an effect. We are going to make it pretty big, equal to -10 mmHg (almost a full SD of the observed SBP values), and add it to the active tx end of period values. 

```{r}

  effect <- -10

  data_long$value_2 <- data_long$value

  tar <- data_long$tx == 2 & data_long$timing == "EoP"

  data_long$value_2[tar] <- data_long$value_2[tar] + effect
  
  data_long$ep_2 <- data_long$ep
  
  data_long$ep_2[tar] <- data_long$ep_2[tar] + effect

```

Now just repeat everything we did before, replacing value_2 for value. 
 
```{r cross_over_plot_2}

  ggplot(data_long, aes(x = time2, y = value_2, group = subj_id)) +
    geom_line(data = filter(data_long, as.numeric(time) < 3), alpha = 0.2,
              aes(color = treatment_p1)) +
    geom_smooth(data = filter(data_long, as.numeric(time) < 3), method = "lm",
                aes(color = treatment_p1, linetype = treatment_p1,
                group = treatment_p1),
                se = FALSE, size = 2) +
    geom_line(data = filter(data_long, as.numeric(time) > 2), alpha = 0.2,
              aes(color = treatment_p2)) +
    geom_smooth(data = filter(data_long, as.numeric(time) > 2), method = "lm",
                aes(color = treatment_p2, linetype = treatment_p2,
                    group = treatment_p2),
                se = FALSE, size = 2) +
    scale_linetype(guide = FALSE) +
    theme_minimal() +
    scale_color_brewer("Tx", palette = "Set1") +
    theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
    scale_x_discrete(labels = c("Start P1", "End P1", "Start P2", "End P2")) +
    xlab("") +
    ylab("SBP mmHg")

```


```{r distribution_plot_2}

  ggplot(data_long, aes(x = value_2, fill = tx, color = tx)) +
    geom_density(alpha = 0.7) +
    geom_rug() +
    scale_fill_brewer("Tx", palette = "Set1") +
    scale_color_brewer("Tx", palette = "Set1") +
    facet_wrap(~period + timing) +
    theme_minimal() +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
    ylab("") +
    xlab("SBP mmHg")

```


```{r models_2}

# Models

# Re-configure the data so we can adjust for period-specific baselines if we
# want to. 

  me_sbp_df <- full_join(
    select(data_long, subj_id, sex, period, bl, tx) %>%   filter(!is.na(bl)),
    select(data_long, subj_id, sex, period, ep_2, tx) %>% filter(!is.na(ep_2)),
    by = c("subj_id", "period", "tx", "sex")
  ) %>%
    mutate(bl = scale(bl, scale = FALSE))


# 4 models. Adjust for sex; + period; +tx*period interaction; +bl
  me_sbp     <- lmer(ep_2 ~ tx + sex +               (1 | subj_id),
                     data = me_sbp_df)
  me_sbp_p   <- lmer(ep_2 ~ tx + sex + period +      (1 | subj_id),
                     data = me_sbp_df)
  me_sbp_int <- lmer(ep_2 ~ tx * period +  sex +     (1 | subj_id),
                     data = me_sbp_df)
  me_sbp_bl  <- lmer(ep_2 ~ tx + sex + period + bl + (1 | subj_id),
                     data = me_sbp_df)

  labs <- c("Intercept", "Treatment", "Sex", "Period")

  tab_model(
    me_sbp, me_sbp_p, me_sbp_bl,
    p.val = "kr",
    pred.labels = c(labs, "SBP Baseline"),
    dv.labels = c("Unadjusted", "+ Period effect", "+ Baselines")
    )

```



